{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Yandex DataSphere Kernel",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "file_extension": ".py",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "notebookId": "6bb475f0-e440-4eaa-807f-09a2eb8cb938",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "hw2-student.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Homework 2: CTC Speech Recognition System\n",
    "You can do this notebook in google collab, or in datasphere (if you are brave enougth)\n",
    "\n",
    "### Grades criteria\n",
    "\n",
    "```\n",
    "[ ] (10 points) Implement a Prefix Decoder\n",
    "[ ] (10 points) Train ASR System, WER criterions: 60-50 -- 3 points, 50-40 -- 5 points, 40-35 -- 7 points, <=35 -- 10 points. + Bonus point per 1% WER below 30\n",
    "[ ] (5 points) Compare performance of DNN, RNN and BiRNN models in terms of WER, training time and other properties\n",
    "[ ] (5 points) Compare alignments obtained from DNN, RNN and BiRNN models\n",
    "```\n",
    "\n",
    "The results of this task are two artifacts:\n",
    "1. this Jupiter Notebook (`.ipynb`) with completed cells, training progress and final score.\n",
    "2. file with predictions of your best model for the test data\n",
    "\n",
    "Save the artifacts to a directory named `{your last name}_{your first name}_hw2` and pack them in `.zip` archive.\n"
   ],
   "metadata": {
    "id": "MK6bCSji-oa1",
    "cellId": "z5qfpgxviokgo9ewdahyxr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "#pip install torch==1.8.0+cu101\n",
    "%pip install torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "%pip install https://github.com/kpu/kenlm/archive/master.zip\n",
    "%pip install dulwich\n",
    "%pip install --user -U arpa\n",
    "    \n",
    "%enable_full_walk"
   ],
   "metadata": {
    "id": "WWDmSBBn-07C",
    "cellId": "na65u400yyes9ya34xsbvm",
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Defaulting to user installation because normal site-packages is not writeable\nLooking in links: https://download.pytorch.org/whl/torch_stable.html\nRequirement already satisfied: torchaudio==0.8.0 in /home/jupyter/.local/lib/python3.7/site-packages (0.8.0)\nRequirement already satisfied: torch==1.8.0 in /home/jupyter/.local/lib/python3.7/site-packages (from torchaudio==0.8.0) (1.8.0+rocm4.0.1)\nRequirement already satisfied: numpy in /kernel/lib/python3.7/site-packages (from torch==1.8.0->torchaudio==0.8.0) (1.19.4)\nRequirement already satisfied: typing-extensions in /kernel/lib/python3.7/site-packages (from torch==1.8.0->torchaudio==0.8.0) (3.7.4.3)\nDefaulting to user installation because normal site-packages is not writeable\nCollecting https://github.com/kpu/kenlm/archive/master.zip\n  Using cached https://github.com/kpu/kenlm/archive/master.zip\nDefaulting to user installation because normal site-packages is not writeable\nCollecting dulwich\n  Downloading dulwich-0.20.21-cp37-cp37m-manylinux2010_x86_64.whl (515 kB)\n\u001b[K     |████████████████████████████████| 515 kB 3.5 MB/s \n\u001b[?25hRequirement already satisfied: certifi in /kernel/lib/python3.7/site-packages (from dulwich) (2020.12.5)\nRequirement already satisfied: urllib3>=1.24.1 in /kernel/lib/python3.7/site-packages (from dulwich) (1.26.4)\nInstalling collected packages: dulwich\n\u001b[33m  WARNING: The script dulwich is installed in '/home/jupyter/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\nSuccessfully installed dulwich-0.20.21\nCollecting arpa\n  Downloading arpa-0.1.0b4-py3-none-any.whl (9.6 kB)\nInstalling collected packages: arpa\nSuccessfully installed arpa-0.1.0b4\n"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clone github repo"
   ],
   "metadata": {
    "id": "H046bnEhkIHf",
    "cellId": "4bv5j3c5cgbiqgbxltnrp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "\n",
    "import dulwich.client\n",
    "from dulwich.repo import Repo\n",
    "from dulwich import index\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def git_clone(src, target):\n",
    "    client, path = dulwich.client.get_transport_and_path(src)\n",
    "    if os.path.isdir(target):\n",
    "        shutil.rmtree(target)\n",
    "    os.makedirs(target)\n",
    "    r = Repo.init(target)\n",
    "\n",
    "    remote_refs = client.fetch(src, r)\n",
    "    r[b\"HEAD\"] = remote_refs.refs[b\"HEAD\"]\n",
    "\n",
    "    index.build_index_from_tree(r.path, r.index_path(), r.object_store, r[b'HEAD'].tree)\n",
    "\n",
    "src = \"https://github.com/yandexdataschool/speech_course\"\n",
    "target = \"./speech_course\"\n",
    "\n",
    "git_clone(src, target)\n",
    "os.listdir(target)\n",
    "\n",
    "week_05_path = './speech_course/week_05' # Change this path, if it is different in your case"
   ],
   "metadata": {
    "id": "pelDQHU-_DUy",
    "cellId": "x21q44iq67quhpu1a3zem"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "import importlib\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from speech_course.week_05.utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchaudio\n",
    "from torch import optim\n",
    "import arpa\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ],
   "metadata": {
    "id": "IOaR9CeT-oa7",
    "cellId": "0jg5sfs7qowv79473xsi8eu",
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speech_course'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-497c47c3c9f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeech_course\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweek_05\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speech_course'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "# Download LibriSpeech 100hr training and test data\n",
    "\n",
    "if not os.path.isdir(\"./data\"):\n",
    "    os.makedirs(\"./data\")\n",
    "\n",
    "train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"train-clean-100\", download=True)\n",
    "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"test-clean\", download=True)"
   ],
   "metadata": {
    "id": "Cq8Amv2QAKPU",
    "cellId": "uj668v8qaihxclvkvheq6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizer Class"
   ],
   "metadata": {
    "id": "c79P_B0b-oa8",
    "cellId": "abgm2usdt24l6itvepmw8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "# Class to transform text to strings of token indecies\n",
    "class Tokenizer:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        _ 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_indecies(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['_']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def indecies_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('_', ' ')\n",
    "tokenizer = Tokenizer()"
   ],
   "metadata": {
    "id": "_kzOaLiV-oa8",
    "cellId": "jarxy3gwdllxcqufdtz4f"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "\n",
    "INSERT GREEDY DECODER CODE"
   ],
   "metadata": {
    "id": "Jwc1NZkU-obC",
    "cellId": "jzbg8qm8vcrinevp9y0dok"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "# TESTING THE GREEDY DECODER \n",
    "\n",
    "#Load numpy matrix, add axis [batch,classes,time]\n",
    "matrix = np.loadtxt(os.path.join(week_05_path, 'test_matrix.txt'))[np.newaxis,:,:]\n",
    "\n",
    "# Turn into Torch Tensor of shape [batch, time, classes]\n",
    "matrix = torch.Tensor(matrix).transpose(1,2)\n",
    "\n",
    "# Create list of torch tensor\n",
    "labels_indecies = [torch.Tensor(tokenizer.text_to_indecies('there seems no good reason for believing that it will change'))]\n",
    "\n",
    "# Run the Decoder\n",
    "decodes, targets = GreedyDecoder(matrix, labels_indecies, [len(labels_indecies[0])])\n",
    "\n",
    "assert decodes[0] == 'there se ms no good reason for believing that twillc ange'\n",
    "assert targets[0] == 'there seems no good reason for believing that it will change'\n",
    "\n"
   ],
   "metadata": {
    "id": "m4LozjfI-obD",
    "cellId": "se7g7cudhf1r43b40icy9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement Prefix Decoding With LM (10 points)"
   ],
   "metadata": {
    "cellId": "5usp9pexqf2a1g8vxae8ic"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "NEG_INF = -float(\"inf\")\n",
    "\n",
    "\n",
    "def make_new_beam():\n",
    "    fn = lambda: (NEG_INF, NEG_INF)\n",
    "    return collections.defaultdict(fn)\n",
    "\n",
    "\n",
    "def logsumexp(*args):\n",
    "    \"\"\"\n",
    "    Stable log sum exp.\n",
    "    \"\"\"\n",
    "    if all(a == NEG_INF for a in args):\n",
    "        return NEG_INF\n",
    "    a_max = max(args)\n",
    "    lsp = np.log(sum(np.exp(a - a_max)\n",
    "                       for a in args))\n",
    "    return a_max + lsp\n",
    "\n",
    "def _BeamSearchDecoder(probs, lm, alpha=0.1, beta=2, beam_size=5, blank=28, space=1, prune=1e-5):\n",
    "    \"\"\"\n",
    "    Performs inference for the given output probabilities.\n",
    "    Arguments:\n",
    "        probs: The output probabilities (e.g. post-softmax) for each\n",
    "          time step. Should be an array of shape (time x output dim).\n",
    "        beam_size (int): Size of the beam to use during inference.\n",
    "        blank (int): Index of the CTC blank label.\n",
    "    Returns the output label sequence and the corresponding negative\n",
    "    log-likelihood estimated by the decoder.\n",
    "    \"\"\"\n",
    "    T, S = probs.shape\n",
    "    probs = np.log(probs)\n",
    "    if prune == 0.0:\n",
    "        prune = NEG_INF\n",
    "    else:\n",
    "        prune = np.log(prune)\n",
    "    # Elements in the beam are (prefix, (p_blank, p_no_blank))\n",
    "    # Initialize the beam with the empty sequence, a probability of\n",
    "    # 1 for ending in blank and zero for ending in non-blank\n",
    "    # (in log space).\n",
    "    beam = [(tuple(), (0.0, NEG_INF))]\n",
    "\n",
    "    for t in range(T):  # Loop over time\n",
    "\n",
    "        # A default dictionary to store the next step candidates.\n",
    "        next_beam = make_new_beam()\n",
    "\n",
    "        # The variables p_b and p_nb are respectively the\n",
    "        # probabilities for the prefix given that it ends in a\n",
    "        # blank and does not end in a blank at this time step.\n",
    "        prev_prefixes = [i[0] for i in beam] \n",
    "        for prefix, (p_b, p_nb) in beam:  # Loop over beam\n",
    "            for s in range(S):  # Loop over vocab\n",
    "                p = probs[t, s]\n",
    "                if p > prune: # Prune the vocab\n",
    "                    \n",
    "                    # If we propose a blank the prefix doesn't change.\n",
    "                    # Only the probability of ending in blank gets updated.\n",
    "                    if s == blank:\n",
    "                        \n",
    "                        # Yield next P_blank and P_Not_blank\n",
    "                        <YOUR_CODE>\n",
    "                        \n",
    "                        # Update next P_blank. DO NOT update next P_not_blank\n",
    "                        <YOUR_CODE>\n",
    "                        continue\n",
    "\n",
    "                        \n",
    "                    # Extend the prefix by the new character s and add it to\n",
    "                    # the beam. Only the probability of not ending in blank\n",
    "                    # gets updated.\n",
    "                     <YOUR_CODE>\n",
    "                        \n",
    "                    # Yield next P_blank and P_Not_blank - this is either empty, obtained form existing prefix\n",
    "                     <YOUR_CODE>\n",
    "\n",
    "                    #Situation of repeating last NON-BLANK character\n",
    "                    if s == end_t:\n",
    "                        # We don't include the previous probability of not ending\n",
    "                        # in blank (p_nb) if s is repeated at the end. The CTC\n",
    "                        # algorithm merges characters not separated by a blank.\n",
    "                         <YOUR_CODE>\n",
    "                        \n",
    "                        #we also update the unchanged prefix. This is the merging case.\n",
    "                        <YOUR_CODE>\n",
    "                    # If this is a NEW space (repeat space covered in previous situation)\n",
    "                    elif s == space and lm is not None:\n",
    "                        # Convert new prefix indecies to upper-case string (LM uses upper case!)\n",
    "                        # Remove trailing space\n",
    "                        l=tokenizer.int_to_text(n_prefix).upper().strip()\n",
    "                        \n",
    "                        if len(l.replace(' ', '')) > 0:\n",
    "                            \n",
    "                            # Get LM probability\n",
    "                            lm_prob = lm.log_p(l.strip())\n",
    "\n",
    "                            # Convert to natural log, as ARPA LM uses log10\n",
    "                            lm_prob = lm_prob/np.log10(np.e)\n",
    "\n",
    "                            # Compute next non-blank prob with LM score added\n",
    "                            <YOUR_CODE>\n",
    "                        else:\n",
    "                            <YOUR_CODE>\n",
    "\n",
    "                    # If this is a non-repeat, non-space character\n",
    "                    else:\n",
    "                        n_p_nb = <YOUR_CODE>\n",
    "                        \n",
    "    \n",
    "#                     # Make use of discarded prefixes\n",
    "                    if n_prefix not in prev_prefixes and t>0:\n",
    "                         <YOUR_CODE>\n",
    "                        \n",
    "                    next_beam[n_prefix] = (n_p_b, n_p_nb)\n",
    "\n",
    "    \n",
    "    \n",
    "                        \n",
    "        # Sort and trim the beam before moving on to the next time-step.\n",
    "        if lm is None:\n",
    "            beam = sorted(next_beam.items(),\n",
    "                  key=lambda x: logsumexp(*x[1]),\n",
    "                  reverse=True)\n",
    "        else:\n",
    "            beam = sorted(next_beam.items(),\n",
    "                          # Need to add length bonus here...\n",
    "                          key=lambda x: logsumexp(*x[1])+ <YOUR_CODE>),\n",
    "                          reverse=True)\n",
    "        beam = beam[:beam_size]\n",
    "        prev_beam = next_beam\n",
    "\n",
    "    best = beam[0]\n",
    "    return best[0], -logsumexp(*best[1])\n",
    "\n",
    "def BeamSearchDecoder(probs, labels, label_lengths, input_lengths, lm, beam_size=35, blank=28, space=1, prune=1e-3, alpha=0.1, beta=2):\n",
    "    probs = probs.cpu().detach().numpy()\n",
    "    decodes, targets = [], []\n",
    "    for i, prob in enumerate(probs):\n",
    "\n",
    "        targets.append(tokenizer.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        int_seq, _ = _BeamSearchDecoder(prob[:input_lengths[i]], lm=lm, beam_size=beam_size, blank=blank, prune=prune, alpha=alpha, beta=beta)\n",
    "        decodes.append(tokenizer.int_to_text(int_seq))\n",
    "        \n",
    "    return decodes, targets"
   ],
   "metadata": {
    "cellId": "l2sqrnp6ckupa3ejnjv4",
    "trusted": true
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "# TESTING PREFIX Decoder\n",
    "\n",
    "#Create LM\n",
    "import arpa\n",
    "alm = arpa.loadf('3-gram.pruned.1e-7.arpa')[0]\n",
    "\n",
    "\n",
    "#Load numpy matrix, add axis [batch,classes,time]\n",
    "matrix = np.loadtxt('test_matrix.txt')[np.newaxis,:,:]\n",
    "\n",
    "# Turn into Torch Tensor of shape [batch, time, classes]\n",
    "matrix = torch.Tensor(matrix).transpose(1,2)\n",
    "\n",
    "\n",
    "labels_indecies = [torch.Tensor(tokenizer.text_to_int('there seems no good reason for believing that it will change'))]\n",
    "\n",
    "#Run the Decoder\n",
    "decodes, targets = BeamSearchDecoder(matrix, labels_indecies, [len(labels_indecies[0])], [matrix.size()[1]], lm=None, beam_size=100, prune=1e-3, alpha=0.1, beta=2)\n",
    "\n",
    "\n",
    "assert decodes[0] == 'there se ms no good reason for believing that twil c ange'\n",
    "assert targets[0] == 'there seems no good reason for believing that it will change'\n",
    "\n",
    "decodes, targets = BeamSearchDecoder(matrix, labels_indecies, [len(labels_indecies[0])], [matrix.size()[1]], lm=alm, beam_size=100, prune=1e-3, alpha=0.1, beta=2)\n",
    "\n",
    "\n",
    "assert decodes[0] == 'there seems no good reason for believing that twillc ange'\n",
    "assert targets[0] == 'there seems no good reason for believing that it will change'\n",
    "\n"
   ],
   "metadata": {
    "cellId": "w167u74ao4bsoz3htaa738",
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7195a6fcca8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Turn into Torch Tensor of shape [batch, time, classes]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep Learning part"
   ],
   "metadata": {
    "id": "sr7uip8slCcw",
    "cellId": "zfs3th23sxnnatpxbacw4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Dataloader"
   ],
   "metadata": {
    "id": "sFouWJvO-obE",
    "cellId": "gvc1msqg6viwm3iwt79xy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "# For train you can use SpecAugment data aug here.\n",
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=<YOUR CODE HERE>),\n",
    "    ADD YOUR AUGMENTS HERE\n",
    ")\n",
    "\n",
    "test_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _, _, _) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'test':\n",
    "            spec = test_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(tokenizer.text_to_indecies(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0] // 2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths"
   ],
   "metadata": {
    "id": "6FfDdryM-obF",
    "cellId": "4i95bg5u0c4pj26vvkbxyc"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement a Neural Network Model\n",
    "\n",
    "You should try out a few different model types:\n",
    "- Feed-Forward Model (DNN)\n",
    "- Recurrent Model (GRU or LSTM)\n",
    "- Bidirectional Recurrent Model (bi-GRU or bi-LSTM)\n",
    "- Something different for bonus points\n",
    "\n",
    "Before any of this models you can use convolutional layers, as shown in the example below\n",
    "\n",
    "After your experiments you should write a report with comparison of different models in terms of different features, for example: parameters, training speed, resulting quality, spectrogram properties, and data augmentations. Remember, that for full mark you need to achive good WER \n",
    "\n",
    "WER criterions: 60-50 -- 3 points, 50-40 -- 5 points, 40-35 -- 7 points, <= 35 -- 10 points"
   ],
   "metadata": {
    "id": "RqZcwSweECPH",
    "cellId": "jcex1p3ibgiuabzxa0yw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Our model classes are just examples, you can change them as you want"
   ],
   "metadata": {
    "id": "dPwmQyJP5qOe",
    "cellId": "554tm5fog66g78v4s3at8v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "# Define model\n",
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for CNNs input\"\"\"\n",
    "\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous()  # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous()  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        <YOUR CODE HERE>\n",
    "        x += residual\n",
    "        return x  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats // 2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3 // 2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = <YOUR CODE HERE>\n",
    "        self.birnn_layers = <YOUR CODE HERE>\n",
    "        self.classifier = <YOUR CODE HERE>\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2)  # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "id": "4icyZP5JD9nW",
    "cellId": "b3ddofit6i1f8yjroo07e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Evaluation Code"
   ],
   "metadata": {
    "id": "T27qdd0iEH9q",
    "cellId": "obxpjwwsdlio3sfm7jgtg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "from tqdm import tqdm_notebook"
   ],
   "metadata": {
    "id": "OwZ3lK3DD-LE",
    "cellId": "x03325d7w5ou3qsh5azgrl"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data\n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(spectrograms)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1)  # (time, batch, n_class)\n",
    "\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(spectrograms), data_len,\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch, decode='Greedy', lm=None):\n",
    "    print('Beginning eval...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        for i, _data in enumerate(test_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data\n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "            \n",
    "            matrix = model(spectrograms)  # (batch, time, n_class)\n",
    "            matrix = F.log_softmax(matrix, dim=2)\n",
    "            probs = F.softmax(matrix,dim=2)\n",
    "            matrix = matrix.transpose(0, 1)  # (time, batch, n_class)\n",
    "                \n",
    "            loss = criterion(matrix, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            if decode == 'Greedy':\n",
    "                decoded_preds, decoded_targets = GreedyDecoder(matrix.transpose(0, 1), labels, label_lengths)\n",
    "            elif decode == 'BeamSearch':\n",
    "                ## THIS IS A CLASS YOU SHOULD IMPLEMENT\n",
    "                decoded_preds, decoded_targets = BeamSearchDecoder(probs, labels, label_lengths, input_lengths, lm=lm)\n",
    "            for j in range(len(decoded_preds)):\n",
    "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "    avg_cer = sum(test_cer) / len(test_cer)\n",
    "    avg_wer = sum(test_wer) / len(test_wer)\n",
    "\n",
    "    print(\n",
    "        'Epoch: {:d}, Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(epoch, test_loss,\n",
    "                                                                                                       avg_cer,\n",
    "                                                                                                       avg_wer))"
   ],
   "metadata": {
    "id": "RAA05g-oD-N_",
    "cellId": "hws8dpmno7ymiam3dnafp"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "#pragma async \n",
    "# PRAGMA ASYNC IS NECESSARY FOR TRAINING!\n",
    "torch.manual_seed(7)\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU found! 🎉')\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print('Only CPU found! 💻')\n",
    "    device = 'cpu'\n",
    "\n",
    "verbose=False\n",
    "\n",
    "# Hyperparameters for your model\n",
    "hparams = {\n",
    "    \"n_cnn_layers\": 3,\n",
    "    \"n_rnn_layers\": <YOUR CODE HERE>,\n",
    "    \"rnn_dim\": <YOUR CODE HERE>\n",
    "    \"n_class\": 29,\n",
    "    \"n_feats\": <YOUR CODE HERE>,\n",
    "    \"stride\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\":  5e-4,\n",
    "    \"batch_size\":  10,\n",
    "    \"epochs\": 20\n",
    "}\n",
    "\n",
    "# Define Dataloyour training and test data loaders\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    " train_loader = <YOUR_CODE>\n",
    " test_loader = <YOUR_CODE>\n",
    "\n",
    "# Define ASR Model \n",
    "model = SpeechRecognitionModel(\n",
    "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    ").to(device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if verbose:\n",
    "    print(model)\n",
    "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "#Define optimizineer, criterion, scheduler\n",
    "optimizer = <YOUR CODE>\n",
    "criterion = <YOUR CODE>\n",
    "scheduler = <YOUR CODE> - I suggest OneCycleLR for speed.\n",
    "\n",
    "\n",
    "#iter_meter = IterMeter()\n",
    "start = time.time()\n",
    "print(\"Start training...\")\n",
    "for epoch in range(1, hparams['epochs'] + 1):\n",
    "    ep_start = time.time()\n",
    "    train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "    #if epoch % 2 == 0:\n",
    "    save_checkpoint(model, checkpoint_name=f'model_epoch{epoch}.tar')\n",
    "    load_checkpoint(model, checkpoint_name=f'model_epoch{epoch}.tar', path='./', device=device)\n",
    "    test(model, device, test_loader, criterion, epoch)\n",
    "    print(f\"Time for epoch: {round(time.time() - ep_start, 0)} sec.\")\n",
    "save_checkpoint(model, checkpoint_name=f'model.tar')\n",
    "duration = time.time() - start\n",
    "print(f'Training took {np.round(duration / 60.0, 1)} min.')"
   ],
   "metadata": {
    "id": "ZlAaMjh4D-RD",
    "cellId": "7ezpcofubg6gfyyde5c68"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "# Test the model in Prefix Decode Mode - only do after you have implemented your prefix decoder\n",
    "\n",
    "test(model, device, test_loader, criterion, epoch, decode='BeamSearch', lm=None)\n",
    "\n",
    "alm = arpa.loadf('3-gram.pruned.1e-7.arpa')[0]\n",
    "test(model, device, test_loader, criterion, epoch, decode='BeamSearch', lm=alm)"
   ],
   "metadata": {
    "cellId": "2oj2t9pb6s508m4bomxqr"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Compare different models: DNN, GRU/LSTM, bi-GRU/bi-LSTM (5 points)",
   "metadata": {
    "id": "VGS9rrTK29fx",
    "cellId": "90vk5p1hyhmqhjlztpswx8"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Analyze CTC Alignments (5 points)",
   "metadata": {
    "id": "OvSNEbMngpZU",
    "cellId": "7l42i8cl7mch5fzh42uv8b"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## In this section you should compare alignments obtained from different models.\n\nFor example, you can show:\n\n* Examples of alignments and their analysis\n* Differencies in the properties of alignment distributions over the dataset\n* Dynamic of alignments during training (from checkpoints)\n* Connection between alignments and model loss\n",
   "metadata": {
    "id": "TtcI8Q65xXnJ",
    "cellId": "om7mmrazgrojbft3qos2o"
   }
  },
  {
   "cell_type": "code",
   "source": "#!L\nADD YOUR CODE FOR CTC FORWARD BACKWARD FROM SEMINAR",
   "metadata": {
    "id": "hd2cGenN-oa_",
    "cellId": "hz15vjonrhcd0goeoye94"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "#!L\n# Test your implementation of CTC\n#Load numpy matrix, add axis [classes,time]\nmatrix = np.loadtxt(os.path.join(week_05_path, 'test_matrix.txt'))\n# Create label_sequence\ntokenizer = Tokenizer()\nlabels_indecies = tokenizer.text_to_indecies('there se ms no good reason for believing that twillc ange')\n\nalign = soft_alignment(labels_indecies, matrix)\n\nref_align = np.loadtxt(os.path.join(week_05_path, 'soft_alignment.txt'))\n\nassert np.all(ref_align == align)",
   "metadata": {
    "id": "lyO-qCwG-obA",
    "cellId": "j0hk1mmq56mit6ldayht"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "#Example\nmodel.eval()\n_data = next(iter(test_loader))\nspectrograms, labels, input_lengths, label_lengths = _data\nspectrograms, labels = spectrograms.to(device), labels.to(device)\n\nmatrix = model(spectrograms).transpose(1,2)  # (batch, n_class, time)",
   "metadata": {
    "id": "QAHLTOQGrgew",
    "cellId": "vrt1ufy7fcefeck5i8hfu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Example of alignment calculation:\nwith torch.no_grad():\n  align = soft_alignment(labels[0].int().cpu().numpy(), F.softmax(matrix[0],dim=0).cpu().numpy())",
   "metadata": {
    "id": "fL5dwHiGtL1G",
    "cellId": "b80yoozigvm36ra3tisfbf"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "plt.figure(dpi=150)\nplt.imshow(align, aspect='auto', interpolation='nearest')\nplt.colorbar()\n\nplt.figure(dpi=150)\nplt.imshow(np.log(align), aspect='auto', interpolation='nearest')\nplt.colorbar()",
   "metadata": {
    "id": "DqvHAfyWs7DR",
    "cellId": "t6dtc9k91s90ual4nmzci49"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Conclusions 🧑‍🎓\n\n* What challenges did you encounter while completing this task?\n* What skills have you acquired while doing this task?\n* How difficult did you find this task (on a scale from 0 to 10), and why?\n* What did you like in this homework, and what didn't?",
   "metadata": {
    "id": "muP0QOp_gvdp",
    "cellId": "fgri9tl5qocpkrzz76s53h"
   }
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "id": "0LOcRoW3D-Wu",
    "cellId": "iz6t4tmtlns28i9nn6t64h"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}