{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "z5qfpgxviokgo9ewdahyxr",
    "id": "MK6bCSji-oa1"
   },
   "source": [
    "# Homework 2: CTC Speech Recognition System\n",
    "You can do this notebook in google collab, or in datasphere (if you are brave enougth)\n",
    "\n",
    "### Grades criteria\n",
    "\n",
    "```\n",
    "[ ] (10 points) Implement a Prefix Decoder\n",
    "[ ] (10 points) Train ASR System, WER criterions: 60-50 -- 3 points, 50-40 -- 5 points, 40-35 -- 7 points, <=35 -- 10 points. + Bonus point per 1% WER below 30\n",
    "[ ] (5 points) Compare performance of DNN, RNN and BiRNN models in terms of WER, training time and other properties\n",
    "[ ] (5 points) Compare alignments obtained from DNN, RNN and BiRNN models\n",
    "```\n",
    "\n",
    "The results of this task are two artifacts:\n",
    "1. this Jupiter Notebook (`.ipynb`) with completed cells, training progress and final score.\n",
    "2. file with predictions of your best model for the test data\n",
    "\n",
    "Save the artifacts to a directory named `{your last name}_{your first name}_hw2` and pack them in `.zip` archive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "na65u400yyes9ya34xsbvm",
    "id": "WWDmSBBn-07C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torchaudio==0.8.0 in /home/jupyter/.local/lib/python3.7/site-packages (0.8.0)\n",
      "Requirement already satisfied: torch==1.8.0 in /home/jupyter/.local/lib/python3.7/site-packages (from torchaudio==0.8.0) (1.8.0+rocm4.0.1)\n",
      "Requirement already satisfied: numpy in /home/jupyter/.local/lib/python3.7/site-packages (from torch==1.8.0->torchaudio==0.8.0) (1.17.5)\n",
      "Requirement already satisfied: typing-extensions in /kernel/lib/python3.7/site-packages (from torch==1.8.0->torchaudio==0.8.0) (3.7.4.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Using cached https://github.com/kpu/kenlm/archive/master.zip\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dulwich in /home/jupyter/.local/lib/python3.7/site-packages (0.20.21)\n",
      "Requirement already satisfied: urllib3>=1.24.1 in /kernel/lib/python3.7/site-packages (from dulwich) (1.26.4)\n",
      "Requirement already satisfied: certifi in /kernel/lib/python3.7/site-packages (from dulwich) (2020.12.5)\n",
      "Collecting arpa\n",
      "  Downloading arpa-0.1.0b4-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: arpa\n",
      "Successfully installed arpa-0.1.0b4\n"
     ]
    }
   ],
   "source": [
    "#!L\n",
    "#pip install torch==1.8.0+cu101\n",
    "%pip install torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "%pip install https://github.com/kpu/kenlm/archive/master.zip\n",
    "%pip install dulwich\n",
    "%pip install --user -U arpa\n",
    "    \n",
    "%enable_full_walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4bv5j3c5cgbiqgbxltnrp",
    "id": "H046bnEhkIHf"
   },
   "source": [
    "## Clone github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellId": "x21q44iq67quhpu1a3zem",
    "id": "pelDQHU-_DUy"
   },
   "outputs": [
    {
     "ename": "Execute error",
     "evalue": "Failed to allocate servant L: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!L\n",
    "\n",
    "import dulwich.client\n",
    "from dulwich.repo import Repo\n",
    "from dulwich import index\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def git_clone(src, target):\n",
    "    client, path = dulwich.client.get_transport_and_path(src)\n",
    "    if os.path.isdir(target):\n",
    "        shutil.rmtree(target)\n",
    "    os.makedirs(target)\n",
    "    r = Repo.init(target)\n",
    "\n",
    "    remote_refs = client.fetch(src, r)\n",
    "    r[b\"HEAD\"] = remote_refs.refs[b\"HEAD\"]\n",
    "\n",
    "    index.build_index_from_tree(r.path, r.index_path(), r.object_store, r[b'HEAD'].tree)\n",
    "\n",
    "src = \"https://github.com/yandexdataschool/speech_course\"\n",
    "target = \"./speech_course\"\n",
    "\n",
    "git_clone(src, target)\n",
    "os.listdir(target)\n",
    "\n",
    "week_05_path = './speech_course/week_05' # Change this path, if it is different in your case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "0jg5sfs7qowv79473xsi8eu",
    "id": "IOaR9CeT-oa7"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "import importlib\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from speech_course.week_05.utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchaudio\n",
    "from torch import optim\n",
    "import arpa\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "uj668v8qaihxclvkvheq6",
    "id": "Cq8Amv2QAKPU"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# Download LibriSpeech 100hr training and test data\n",
    "\n",
    "if not os.path.isdir(\"./data\"):\n",
    "    os.makedirs(\"./data\")\n",
    "\n",
    "train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"train-clean-100\", download=True)\n",
    "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"test-clean\", download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "abgm2usdt24l6itvepmw8",
    "id": "c79P_B0b-oa8"
   },
   "source": [
    "## Tokenizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellId": "jarxy3gwdllxcqufdtz4f",
    "id": "_kzOaLiV-oa8"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# Class to transform text to strings of token indecies\n",
    "class Tokenizer:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        _ 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_indecies(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['_']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def indecies_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('_', ' ')\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellId": "jzbg8qm8vcrinevp9y0dok",
    "id": "Jwc1NZkU-obC"
   },
   "outputs": [
    {
     "ename": "Execute error",
     "evalue": "Failed to allocate servant L: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!L\n",
    "def GreedyDecoder(output: torch.Tensor, labels: list, label_lengths: list, blank_label=28, collapse_repeated=True):\n",
    "    \"\"\"ist\n",
    "    :param output: torch.Tensor of Probs or Log-Probs of shape [batch, time, classes]\n",
    "    :param labels: Listof torch.Tensor of label indecies\n",
    "    :param label_lengths:  int of label lengths\n",
    "    :param blank_label:\n",
    "    :param collapse_repeated:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    # Get max class\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "\n",
    "    decodes = []\n",
    "    targets = []\n",
    "\n",
    "    #For targets and decodes remove r\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "\n",
    "        targets.append(tokenizer.indecies_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "\n",
    "        # Remove repeeats, then remove blanks\n",
    "\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j - 1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(tokenizer.indecies_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "se7g7cudhf1r43b40icy9",
    "id": "m4LozjfI-obD"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# TESTING THE GREEDY DECODER \n",
    "\n",
    "#Load numpy matrix, add axis [batch,classes,time]\n",
    "matrix = np.loadtxt(os.path.join(week_05_path, 'test_matrix.txt'))[np.newaxis,:,:]\n",
    "\n",
    "# Turn into Torch Tensor of shape [batch, time, classes]\n",
    "matrix = torch.Tensor(matrix).transpose(1,2)\n",
    "\n",
    "# Create list of torch tensor\n",
    "labels_indecies = [torch.Tensor(tokenizer.text_to_indecies('there seems no good reason for believing that it will change'))]\n",
    "\n",
    "# Run the Decoder\n",
    "decodes, targets = GreedyDecoder(matrix, labels_indecies, [len(labels_indecies[0])])\n",
    "\n",
    "assert decodes[0] == 'there se ms no good reason for believing that twillc ange'\n",
    "assert targets[0] == 'there seems no good reason for believing that it will change'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "5usp9pexqf2a1g8vxae8ic"
   },
   "source": [
    "## Implement Prefix Decoding With LM (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "l2sqrnp6ckupa3ejnjv4"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "NEG_INF = -float(\"inf\")\n",
    "\n",
    "\n",
    "def make_new_beam():\n",
    "    fn = lambda: (NEG_INF, NEG_INF)\n",
    "    return collections.defaultdict(fn)\n",
    "\n",
    "\n",
    "def logsumexp(*args):\n",
    "    \"\"\"\n",
    "    Stable log sum exp.\n",
    "    \"\"\"\n",
    "    if all(a == NEG_INF for a in args):\n",
    "        return NEG_INF\n",
    "    a_max = max(args)\n",
    "    lsp = np.log(sum(np.exp(a - a_max)\n",
    "                       for a in args))\n",
    "    return a_max + lsp\n",
    "\n",
    "def _BeamSearchDecoder(probs, lm, alpha=0.1, beta=2, beam_size=5, blank=28, space=1, prune=1e-5):\n",
    "    \"\"\"\n",
    "    Performs inference for the given output probabilities.\n",
    "    Arguments:\n",
    "        probs: The output probabilities (e.g. post-softmax) for each\n",
    "          time step. Should be an array of shape (time x output dim).\n",
    "        beam_size (int): Size of the beam to use during inference.\n",
    "        blank (int): Index of the CTC blank label.\n",
    "    Returns the output label sequence and the corresponding negative\n",
    "    log-likelihood estimated by the decoder.\n",
    "    \"\"\"\n",
    "    T, S = probs.shape\n",
    "    probs = np.log(probs)\n",
    "    if prune == 0.0:\n",
    "        prune = NEG_INF\n",
    "    else:\n",
    "        prune = np.log(prune)\n",
    "    # Elements in the beam are (prefix, (p_blank, p_no_blank))\n",
    "    # Initialize the beam with the empty sequence, a probability of\n",
    "    # 1 for ending in blank and zero for ending in non-blank\n",
    "    # (in log space).\n",
    "    beam = [(tuple(), (0.0, NEG_INF))]\n",
    "\n",
    "    for t in range(T):  # Loop over time\n",
    "\n",
    "        # A default dictionary to store the next step candidates.\n",
    "        next_beam = make_new_beam()\n",
    "        prev_beam = None\n",
    "\n",
    "        # The variables p_b and p_nb are respectively the\n",
    "        # probabilities for the prefix given that it ends in a\n",
    "        # blank and does not end in a blank at this time step.\n",
    "        prev_prefixes = [i[0] for i in beam]\n",
    "        for prefix, (p_b, p_nb) in beam:  # Loop over beam\n",
    "            for s in range(S):  # Loop over vocab\n",
    "                p = probs[t, s]\n",
    "                if p > prune: # Prune the vocab\n",
    "                    \n",
    "                    # If we propose a blank the prefix doesn't change.\n",
    "                    # Only the probability of ending in blank gets updated.\n",
    "                    if s == blank:\n",
    "                        \n",
    "                        # Yield next P_blank and P_Not_blank\n",
    "                        next_p_blank = p + logsumexp(p_b, p_nb)\n",
    "                        next_p_not_blank = NEG_INF\n",
    "                        \n",
    "                        # Update next P_blank. DO NOT update next P_not_blank\n",
    "                        current_prefix_probas = next_beam[prefix]\n",
    "                        next_beam[prefix] = (\n",
    "                            logsumexp(current_prefix_probas[0], next_p_blank),\n",
    "                            logsumexp(current_prefix_probas[1], next_p_not_blank)\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                        \n",
    "                    # Extend the prefix by the new character s and add it to\n",
    "                    # the beam. Only the probability of not ending in blank\n",
    "                    # gets updated.\n",
    "                    n_p_b = NEG_INF\n",
    "                    n_p_nb = p + p_b\n",
    "                    n_prefix = prefix + (s, )\n",
    "                    current_prefix_probas = next_beam[n_prefix]\n",
    "                    next_beam[n_prefix] = (\n",
    "                        logsumexp(current_prefix_probas[0], n_p_b),\n",
    "                        logsumexp(current_prefix_probas[1], n_p_nb)\n",
    "                    )\n",
    "                    end_t = prefix[-1] if len(prefix) else None\n",
    "\n",
    "                    # Yield next P_blank and P_Not_blank - this is either empty, obtained form existing prefix\n",
    "                    n_p_b = NEG_INF\n",
    "                    n_p_nb = NEG_INF \n",
    "\n",
    "                    #Situation of repeating last NON-BLANK character\n",
    "                    if s == end_t:\n",
    "                        # We don't include the previous probability of not ending\n",
    "                        # in blank (p_nb) if s is repeated at the end. The CTC\n",
    "                        # algorithm merges characters not separated by a blank.\n",
    "                        n_prefix = prefix\n",
    "                        \n",
    "                        #we also update the unchanged prefix. This is the merging case.\n",
    "                        n_p_nb = p + p_nb\n",
    "                        \n",
    "                    # If this is a NEW space (repeat space covered in previous situation)\n",
    "                    elif s == space and lm is not None:\n",
    "                        # Convert new prefix indecies to upper-case string (LM uses upper case!)\n",
    "                        # Remove trailing space\n",
    "                        l=tokenizer.int_to_text(n_prefix).upper().strip()\n",
    "                        \n",
    "                        if len(l.replace(' ', '')) > 0:\n",
    "                            \n",
    "                            # Get LM probability\n",
    "                            lm_prob = lm.log_p(l.strip())\n",
    "\n",
    "                            # Convert to natural log, as ARPA LM uses log10\n",
    "                            lm_prob = lm_prob/np.log10(np.e)\n",
    "\n",
    "                            # Compute next non-blank prob with LM score added\n",
    "                            # <YOUR_CODE>\n",
    "                            pass\n",
    "                        else:\n",
    "                            pass\n",
    "                            # <YOUR_CODE>\n",
    "\n",
    "                    # If this is a non-repeat, non-space character\n",
    "                    else:\n",
    "                        n_p_nb = p + p_nb\n",
    "                        \n",
    "    \n",
    "                    # Make use of discarded prefixes\n",
    "                    if n_prefix not in prev_prefixes and t > 0:\n",
    "                        prev_prefix_probas = prev_beam[n_prefix]\n",
    "                        n_p_b = logsumexp(prev_prefix_probas[0], n_p_b)\n",
    "                        n_p_nb = logsumexp(prev_prefix_probas[1], n_p_nb)\n",
    "                        \n",
    "                    current_prefix_probas = next_beam[n_prefix]\n",
    "                    n_p_b = logsumexp(current_prefix_probas[0], n_p_b)\n",
    "                    n_p_nb = logsumexp(current_prefix_probas[1], n_p_nb)\n",
    "                    next_beam[n_prefix] = (n_p_b, n_p_nb)\n",
    "    \n",
    "                        \n",
    "        # Sort and trim the beam before moving on to the next time-step.\n",
    "        if lm is None:\n",
    "            beam = sorted(next_beam.items(),\n",
    "                  key=lambda x: logsumexp(*x[1]),\n",
    "                  reverse=True)\n",
    "        else:\n",
    "            beam = sorted(next_beam.items(),\n",
    "                          # Need to add length bonus here...\n",
    "                          key=lambda x: logsumexp(*x[1])+ 0, # <YOUR_CODE>),\n",
    "                          reverse=True)\n",
    "        beam = beam[:beam_size]\n",
    "        prev_beam = next_beam\n",
    "\n",
    "    best = beam[0]\n",
    "    return best[0], -logsumexp(*best[1])\n",
    "\n",
    "def BeamSearchDecoder(probs, labels, label_lengths, input_lengths, lm, beam_size=35, blank=28, space=1, prune=1e-3, alpha=0.1, beta=2):\n",
    "    probs = probs.cpu().detach().numpy()\n",
    "    decodes, targets = [], []\n",
    "    for i, prob in enumerate(probs):\n",
    "\n",
    "        targets.append(tokenizer.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        int_seq, _ = _BeamSearchDecoder(prob[:input_lengths[i]], lm=lm, beam_size=beam_size, blank=blank, prune=prune, alpha=alpha, beta=beta)\n",
    "        decodes.append(tokenizer.int_to_text(int_seq))\n",
    "        \n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "w167u74ao4bsoz3htaa738"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# TESTING PREFIX Decoder\n",
    "\n",
    "#Create LM\n",
    "import arpa\n",
    "alm = arpa.loadf('3-gram.pruned.1e-7.arpa')[0]\n",
    "\n",
    "\n",
    "#Load numpy matrix, add axis [batch,classes,time]\n",
    "matrix = np.loadtxt('test_matrix.txt')[np.newaxis,:,:]\n",
    "\n",
    "# Turn into Torch Tensor of shape [batch, time, classes]\n",
    "matrix = torch.Tensor(matrix).transpose(1,2)\n",
    "\n",
    "\n",
    "labels_indecies = [torch.Tensor(tokenizer.text_to_int('there seems no good reason for believing that it will change'))]\n",
    "\n",
    "#Run the Decoder\n",
    "decodes, targets = BeamSearchDecoder(matrix, labels_indecies, [len(labels_indecies[0])], [matrix.size()[1]], lm=None, beam_size=100, prune=1e-3, alpha=0.1, beta=2)\n",
    "\n",
    "\n",
    "assert decodes[0] == 'there se ms no good reason for believing that twil c ange'\n",
    "assert targets[0] == 'there seems no good reason for believing that it will change'\n",
    "\n",
    "decodes, targets = BeamSearchDecoder(matrix, labels_indecies, [len(labels_indecies[0])], [matrix.size()[1]], lm=alm, beam_size=100, prune=1e-3, alpha=0.1, beta=2)\n",
    "\n",
    "\n",
    "assert decodes[0] == 'there seems no good reason for believing that twillc ange'\n",
    "assert targets[0] == 'there seems no good reason for believing that it will change'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zfs3th23sxnnatpxbacw4",
    "id": "sr7uip8slCcw"
   },
   "source": [
    "## Deep Learning part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "gvc1msqg6viwm3iwt79xy",
    "id": "sFouWJvO-obE"
   },
   "source": [
    "## Create a Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "4i95bg5u0c4pj26vvkbxyc",
    "id": "6FfDdryM-obF"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# For train you can use SpecAugment data aug here.\n",
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=<YOUR CODE HERE>),\n",
    "    ADD YOUR AUGMENTS HERE\n",
    ")\n",
    "\n",
    "test_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _, _, _) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'test':\n",
    "            spec = test_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(tokenizer.text_to_indecies(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0] // 2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "jcex1p3ibgiuabzxa0yw",
    "id": "RqZcwSweECPH"
   },
   "source": [
    "## Implement a Neural Network Model\n",
    "\n",
    "You should try out a few different model types:\n",
    "- Feed-Forward Model (DNN)\n",
    "- Recurrent Model (GRU or LSTM)\n",
    "- Bidirectional Recurrent Model (bi-GRU or bi-LSTM)\n",
    "- Something different for bonus points\n",
    "\n",
    "Before any of this models you can use convolutional layers, as shown in the example below\n",
    "\n",
    "After your experiments you should write a report with comparison of different models in terms of different features, for example: parameters, training speed, resulting quality, spectrogram properties, and data augmentations. Remember, that for full mark you need to achive good WER \n",
    "\n",
    "WER criterions: 60-50 -- 3 points, 50-40 -- 5 points, 40-35 -- 7 points, <= 35 -- 10 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "554tm5fog66g78v4s3at8v",
    "id": "dPwmQyJP5qOe"
   },
   "source": [
    "### Our model classes are just examples, you can change them as you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "b3ddofit6i1f8yjroo07e",
    "id": "4icyZP5JD9nW"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# Define model\n",
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for CNNs input\"\"\"\n",
    "\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous()  # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous()  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        <YOUR CODE HERE>\n",
    "        x += residual\n",
    "        return x  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats // 2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3 // 2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = <YOUR CODE HERE>\n",
    "        self.birnn_layers = <YOUR CODE HERE>\n",
    "        self.classifier = <YOUR CODE HERE>\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2)  # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "obxpjwwsdlio3sfm7jgtg",
    "id": "T27qdd0iEH9q"
   },
   "source": [
    "## Training and Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "x03325d7w5ou3qsh5azgrl",
    "id": "OwZ3lK3DD-LE"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hws8dpmno7ymiam3dnafp",
    "id": "RAA05g-oD-N_"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data\n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(spectrograms)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1)  # (time, batch, n_class)\n",
    "\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(spectrograms), data_len,\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch, decode='Greedy', lm=None):\n",
    "    print('Beginning eval...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        for i, _data in enumerate(test_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data\n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "            \n",
    "            matrix = model(spectrograms)  # (batch, time, n_class)\n",
    "            matrix = F.log_softmax(matrix, dim=2)\n",
    "            probs = F.softmax(matrix,dim=2)\n",
    "            matrix = matrix.transpose(0, 1)  # (time, batch, n_class)\n",
    "                \n",
    "            loss = criterion(matrix, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            if decode == 'Greedy':\n",
    "                decoded_preds, decoded_targets = GreedyDecoder(matrix.transpose(0, 1), labels, label_lengths)\n",
    "            elif decode == 'BeamSearch':\n",
    "                ## THIS IS A CLASS YOU SHOULD IMPLEMENT\n",
    "                decoded_preds, decoded_targets = BeamSearchDecoder(probs, labels, label_lengths, input_lengths, lm=lm)\n",
    "            for j in range(len(decoded_preds)):\n",
    "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "    avg_cer = sum(test_cer) / len(test_cer)\n",
    "    avg_wer = sum(test_wer) / len(test_wer)\n",
    "\n",
    "    print(\n",
    "        'Epoch: {:d}, Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(epoch, test_loss,\n",
    "                                                                                                       avg_cer,\n",
    "                                                                                                       avg_wer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "7ezpcofubg6gfyyde5c68",
    "id": "ZlAaMjh4D-RD"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "#pragma async \n",
    "# PRAGMA ASYNC IS NECESSARY FOR TRAINING!\n",
    "torch.manual_seed(7)\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU found! 🎉')\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print('Only CPU found! 💻')\n",
    "    device = 'cpu'\n",
    "\n",
    "verbose=False\n",
    "\n",
    "# Hyperparameters for your model\n",
    "hparams = {\n",
    "    \"n_cnn_layers\": 3,\n",
    "    \"n_rnn_layers\": <YOUR CODE HERE>,\n",
    "    \"rnn_dim\": <YOUR CODE HERE>\n",
    "    \"n_class\": 29,\n",
    "    \"n_feats\": <YOUR CODE HERE>,\n",
    "    \"stride\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\":  5e-4,\n",
    "    \"batch_size\":  10,\n",
    "    \"epochs\": 20\n",
    "}\n",
    "\n",
    "# Define Dataloyour training and test data loaders\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    " train_loader = <YOUR_CODE>\n",
    " test_loader = <YOUR_CODE>\n",
    "\n",
    "# Define ASR Model \n",
    "model = SpeechRecognitionModel(\n",
    "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    ").to(device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if verbose:\n",
    "    print(model)\n",
    "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "#Define optimizineer, criterion, scheduler\n",
    "optimizer = <YOUR CODE>\n",
    "criterion = <YOUR CODE>\n",
    "scheduler = <YOUR CODE> - I suggest OneCycleLR for speed.\n",
    "\n",
    "\n",
    "#iter_meter = IterMeter()\n",
    "start = time.time()\n",
    "print(\"Start training...\")\n",
    "for epoch in range(1, hparams['epochs'] + 1):\n",
    "    ep_start = time.time()\n",
    "    train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "    #if epoch % 2 == 0:\n",
    "    save_checkpoint(model, checkpoint_name=f'model_epoch{epoch}.tar')\n",
    "    load_checkpoint(model, checkpoint_name=f'model_epoch{epoch}.tar', path='./', device=device)\n",
    "    test(model, device, test_loader, criterion, epoch)\n",
    "    print(f\"Time for epoch: {round(time.time() - ep_start, 0)} sec.\")\n",
    "save_checkpoint(model, checkpoint_name=f'model.tar')\n",
    "duration = time.time() - start\n",
    "print(f'Training took {np.round(duration / 60.0, 1)} min.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "2oj2t9pb6s508m4bomxqr"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# Test the model in Prefix Decode Mode - only do after you have implemented your prefix decoder\n",
    "\n",
    "test(model, device, test_loader, criterion, epoch, decode='BeamSearch', lm=None)\n",
    "\n",
    "alm = arpa.loadf('3-gram.pruned.1e-7.arpa')[0]\n",
    "test(model, device, test_loader, criterion, epoch, decode='BeamSearch', lm=alm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "90vk5p1hyhmqhjlztpswx8",
    "id": "VGS9rrTK29fx"
   },
   "source": [
    "## Compare different models: DNN, GRU/LSTM, bi-GRU/bi-LSTM (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7l42i8cl7mch5fzh42uv8b",
    "id": "OvSNEbMngpZU"
   },
   "source": [
    "## Analyze CTC Alignments (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "om7mmrazgrojbft3qos2o",
    "id": "TtcI8Q65xXnJ"
   },
   "source": [
    "## In this section you should compare alignments obtained from different models.\n",
    "\n",
    "For example, you can show:\n",
    "\n",
    "* Examples of alignments and their analysis\n",
    "* Differencies in the properties of alignment distributions over the dataset\n",
    "* Dynamic of alignments during training (from checkpoints)\n",
    "* Connection between alignments and model loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hz15vjonrhcd0goeoye94",
    "id": "hd2cGenN-oa_"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "ADD YOUR CODE FOR CTC FORWARD BACKWARD FROM SEMINAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "j0hk1mmq56mit6ldayht",
    "id": "lyO-qCwG-obA"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# Test your implementation of CTC\n",
    "#Load numpy matrix, add axis [classes,time]\n",
    "matrix = np.loadtxt(os.path.join(week_05_path, 'test_matrix.txt'))\n",
    "# Create label_sequence\n",
    "tokenizer = Tokenizer()\n",
    "labels_indecies = tokenizer.text_to_indecies('there se ms no good reason for believing that twillc ange')\n",
    "\n",
    "align = soft_alignment(labels_indecies, matrix)\n",
    "\n",
    "ref_align = np.loadtxt(os.path.join(week_05_path, 'soft_alignment.txt'))\n",
    "\n",
    "assert np.all(ref_align == align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "vrt1ufy7fcefeck5i8hfu",
    "id": "QAHLTOQGrgew"
   },
   "outputs": [],
   "source": [
    "#Example\n",
    "model.eval()\n",
    "_data = next(iter(test_loader))\n",
    "spectrograms, labels, input_lengths, label_lengths = _data\n",
    "spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "matrix = model(spectrograms).transpose(1,2)  # (batch, n_class, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "b80yoozigvm36ra3tisfbf",
    "id": "fL5dwHiGtL1G"
   },
   "outputs": [],
   "source": [
    "# Example of alignment calculation:\n",
    "with torch.no_grad():\n",
    "  align = soft_alignment(labels[0].int().cpu().numpy(), F.softmax(matrix[0],dim=0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "t6dtc9k91s90ual4nmzci49",
    "id": "DqvHAfyWs7DR"
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(align, aspect='auto', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.log(align), aspect='auto', interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "fgri9tl5qocpkrzz76s53h",
    "id": "muP0QOp_gvdp"
   },
   "source": [
    "### Conclusions 🧑‍🎓\n",
    "\n",
    "* What challenges did you encounter while completing this task?\n",
    "* What skills have you acquired while doing this task?\n",
    "* How difficult did you find this task (on a scale from 0 to 10), and why?\n",
    "* What did you like in this homework, and what didn't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "iz6t4tmtlns28i9nn6t64h",
    "id": "0LOcRoW3D-Wu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw2-student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notebookId": "45ae85d9-298a-41af-a722-94655056b34f",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
