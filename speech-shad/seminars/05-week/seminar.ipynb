{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "z5qfpgxviokgo9ewdahyxr"
   },
   "source": [
    "# Seminar 3: CTC Forward-Backward and Greedy Decoder\n",
    "\n",
    "The goal of this seminar is to implement the CTC Forward-Backward algorith for Soft-Alignment and Greedy Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "0jg5sfs7qowv79473xsi8eu"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchaudio\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "abgm2usdt24l6itvepmw8"
   },
   "source": [
    "## Tokenizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "jarxy3gwdllxcqufdtz4f"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# Class to transform text to strings of token indecies\n",
    "class Tokenizer:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        _ 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_indecies(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['_']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def indecies_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('_', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3lkqllygp9flmj29013zsg"
   },
   "source": [
    "## Obtain Soft-Alignment via CTC Forward-Backward Algorithm (8 points)\n",
    "\n",
    "Use your newfound knowledge of the CTC forward-backward algorithm to obtain a soft-alignment\n",
    "\n",
    "Remember, that the forward variable is computed as follows:\n",
    "\n",
    "$$\n",
    "  \\begin{aligned}\n",
    "    &\\alpha_t(0) = 0, \\forall t & \\\\\n",
    "    &\\alpha_1(1) = {\\tt P}(z_1 = \\epsilon | \\mathbf{X}_{1:T}), &\\\\\n",
    "    &\\alpha_1(2) = {\\tt P}(z_1 = \\omega^{'}_2 | \\mathbf{X}_{1:T}), &\\\\\n",
    "    &\\alpha_1(s) = 0,\\ \\forall s > 2 &\\\\\n",
    "    &\\alpha_t(s) = 0,\\ \\forall s < (2L+1) -2(T-t) -1 &  \\text{top right zeros}\\\\\n",
    "    &\\alpha_t(s) = \\left \\{\n",
    "  \\begin{aligned}\n",
    "    &\\big(\\alpha_{t-1}(s) + \\alpha_{t-1}(s-1) \\big) {\\tt P}(z_t = \\omega^{'}_s | \\mathbf{X}_{1:T}) & \\text{if}\\ \\omega_s^{'} = \\epsilon\\ \\text{or}\\\n",
    "    \\omega_s^{'} = \\omega_{s-2}^{'} \\\\\n",
    "    &\\big(\\alpha_{t-1}(s) + \\alpha_{t-1}(s-1) + \\alpha_{t-1}(s-2)\\big) {\\tt P}(z_t = \\omega^{'}_s | \\mathbf{X}_{1:T}) & \\text{otherwise}\\\\\n",
    "  \\end{aligned} \\right. \n",
    "  \\end{aligned}\n",
    "$$\n",
    "\n",
    "Backward Variable is computeed like so:\n",
    "\n",
    "$$\n",
    "  \\begin{aligned}\n",
    "    &\\beta_T(2L+1) = 1 &\\\\\n",
    "    &\\beta_T(2L) = 1 & \\\\\n",
    "    &\\beta_T(s) = 0, \\forall s < 2L &\\\\\n",
    "    &\\beta_t(s) = 0,\\ \\forall s > 2t &\\\\\n",
    "    &\\beta_t(2L+2) = 0,\\ \\forall t  & \\text{Bottom left zeros} \\\\\n",
    "    &\\beta_t(s) = \\left \\{\n",
    "  \\begin{aligned}\n",
    "    &\\big(\\beta_{t+1}(s) + \\beta_{t+1}(s+1) \\big) {\\tt P}(z_t = \\omega^{'}_s | \\mathbf{X}_{1:T}) & \\text{if}\\ \\omega_s^{'} = \\epsilon\\ \\text{or}\\\n",
    "    \\omega_s^{'} = \\omega_{s+2}^{'} \\\\\n",
    "    &\\big(\\beta_{t+1}(s) +\\beta_{t+1}(s+1) + \\beta_{t+1}(s+2)\\big) {\\tt P}(z_t = \\omega^{'}_s | \\mathbf{X}_{1:T}) & \\text{otherwise}\\\\\n",
    "  \\end{aligned} \\right. \n",
    "  \\end{aligned}\n",
    "$$\n",
    "\n",
    "The alignment is then given as:\n",
    "\n",
    "$$\n",
    "  \\text{align}_t(s) = \\frac{\\alpha_t(s)\\beta_t(s)}{\\sum_{s}\\alpha_t(s)\\beta_t(s)}\n",
    "$$\n",
    "\n",
    "\n",
    "Doing the computation in Probability space can be numerically unstable, so you should do it in Log-Space using the\n",
    "provided logsumexp operation. Remember to return to prob space at the end. You should get something like:\n",
    "\n",
    "<img src=\"alignment.png\">\n",
    "\n",
    "If you convert the alignment to log-space it will look like:\n",
    "\n",
    "<img src=\"alignment_log.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cellId": "hz15vjonrhcd0goeoye94"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "from matplotlib.colors import LogNorm\n",
    "# Stable log sum exp\n",
    "NEG_INF = -float(\"inf\")\n",
    "def logsumexp(*args):\n",
    "    \"\"\"\n",
    "    Stable log sum exp.\n",
    "    \"\"\"\n",
    "    if all(a == NEG_INF for a in args):\n",
    "        return NEG_INF\n",
    "    a_max = max(args)\n",
    "    lsp = math.log(sum(math.exp(a - a_max)\n",
    "                       for a in args))\n",
    "    return a_max + lsp\n",
    "\n",
    "\n",
    "def forward_algorithm(sequence, matrix, blank=28):\n",
    "    # Matrix is has shape [K, T]\n",
    "\n",
    "    # Turn probs into log-probs\n",
    "    matrix = np.log(matrix)\n",
    "\n",
    "    # Create modified sequence which with START, END blanks and between each character\n",
    "    mod_sequence = [sequence[int((i-1)/2)] if i % 2 !=0 else blank for i in range(len(sequence)*2+1)]\n",
    "\n",
    "    # Initialze\n",
    "    alphas = np.full([len(mod_sequence), matrix.shape[1]], NEG_INF)\n",
    "\n",
    "    for t in range(matrix.shape[1]):\n",
    "        for s in range(len(mod_sequence)):\n",
    "            #First Step\n",
    "            if t == 0:\n",
    "                <YOUR CODE HERE>\n",
    "\n",
    "            # Upper diagonal zeros\n",
    "            elif <YOUR CODE HERE>:\n",
    "                <YOUR CODE HERE>\n",
    "            else:\n",
    "                # Need to do this stabily\n",
    "                if s == 0:\n",
    "                    <YOUR CODE HERE>\n",
    "\n",
    "                elif s == 1:\n",
    "                    <YOUR CODE HERE>\n",
    "\n",
    "                else:\n",
    "                    <YOUR CODE HERE>\n",
    "    return alphas\n",
    "\n",
    "def backward_algorithm(sequence, matrix, blank=28):\n",
    "    # Matrix has shape [K, T] where K - 29 \n",
    "\n",
    "    # Turn probs into log-probs\n",
    "    matrix = np.log(matrix)\n",
    "\n",
    "    # Create modified sequence which with START, END blanks and between each character\n",
    "    mod_sequence = [sequence[int((i-1)/2)] if i % 2 !=0 else blank for i in range(len(sequence)*2+1)]\n",
    "\n",
    "    betas = np.full([len(mod_sequence), matrix.shape[1]], NEG_INF)\n",
    "\n",
    "    for t in reversed(range(matrix.shape[1])):\n",
    "        for s in reversed(range(len(mod_sequence))):\n",
    "            #First Step\n",
    "            if t == matrix.shape[1]-1:\n",
    "                <YOUR CODE HERE>\n",
    "\n",
    "            #Lower Diagonal Zeros\n",
    "            elif <YOUR CODE HERE>:\n",
    "                <YOUR CODE HERE>\n",
    "            else:\n",
    "                if s == len(mod_sequence)-1:\n",
    "                    <YOUR CODE HERE>\n",
    "\n",
    "                elif s == len(mod_sequence)-2:\n",
    "                    <YOUR CODE HERE>\n",
    "\n",
    "                else:\n",
    "                    <YOUR CODE HERE>\n",
    "    return betas\n",
    "\n",
    "def soft_alignment(labels_indecies, matrix):\n",
    "    alphas = forward_algorithm(labels_indecies, matrix)\n",
    "    betas = backward_algorithm(labels_indecies, matrix)\n",
    "\n",
    "    # Move from log space back to prob space\n",
    "    align = <YOUR CODE>\n",
    "\n",
    "    # Normalize Alignment\n",
    "    align = <YOUR CODE>\n",
    "\n",
    "    return align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellId": "j0hk1mmq56mit6ldayht"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# Test your implementation\n",
    "\n",
    "#Load numpy matrix, add axis [classes,time]\n",
    "matrix = np.loadtxt('test_matrix.txt')\n",
    "# Create label_sequence\n",
    "labels_indecies = tokenizer.text_to_indecies('there se ms no good reason for believing that twillc ange')\n",
    "\n",
    "align = soft_alignment(labels_indecies, matrix)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.imshow(align, aspect='auto', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.log(align), aspect='auto', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "ref_align = np.loadtxt('soft_alignment.txt')\n",
    "\n",
    "assert np.allclose(ref_align, align)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "eignaazwtkqbepk36j4zm"
   },
   "source": [
    "## Implement a Greedy Best-Path Decoder! (2 points)\n",
    "\n",
    "Your goal is to implement a Greedy Best-Path decoder. Remember than in CTC the joint distribution over states factors out into a product of marginals:\n",
    "\n",
    "$${\\tt P}(\\mathbf{z}_{1:T}|\\mathbf{X}_{1:T},\\mathbf{\\theta}) = \\prod_{1:T}^T{\\tt P}(z_t|\\mathbf{X}_{1:T},\\mathbf{\\theta})$$\n",
    "\n",
    "Mostly likely state sequence is:\n",
    "\n",
    "$$\\mathbf{\\pi}^*_{1:T} = \\arg \\max_{\\mathbf{pi}_{1:T} } \\prod_{t=1}^T {\\tt P}(z_t = \\pi_t|\\mathbf{X}_{1:T})$$\n",
    "\n",
    "Then merge repeats and remove blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "jzbg8qm8vcrinevp9y0dok"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def GreedyDecoder(output: torch.Tensor, labels: list, label_lengths: list, blank_label=28, collapse_repeated=True):\n",
    "    \"\"\"ist\n",
    "    :param output: torch.Tensor of Probs or Log-Probs of shape [batch, time, classes]\n",
    "    :param labels: Listof torch.Tensor of label indecies\n",
    "    :param label_lengths:  int of label lengths\n",
    "    :param blank_label:\n",
    "    :param collapse_repeated:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    # Get max class\n",
    "    arg_maxes = <YOUR_CODE>\n",
    "\n",
    "    decodes = []\n",
    "    targets = []\n",
    "\n",
    "    #For targets and decodes remove r\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "\n",
    "        targets.append(tokenizer.indecies_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "\n",
    "        # Remove repeeats, then remove blanks\n",
    "\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j - 1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(tokenizer.indecies_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "se7g7cudhf1r43b40icy9"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# TESTING THE GREEDY DECODER\n",
    "\n",
    "#Load numpy matrix, add axis [batch,classes,time]\n",
    "matrix = np.loadtxt('test_matrix.txt')[np.newaxis,:,:]\n",
    "\n",
    "# Turn into Torch Tensor of shape [batch, time, classes]\n",
    "matrix = torch.Tensor(matrix).transpose(1,2)\n",
    "\n",
    "# Create list of torch tensor\n",
    "labels_indecies = [torch.Tensor(tokenizer.text_to_indecies('there seems no good reason for believing that it will change'))]\n",
    "\n",
    "# Run the Decoder\n",
    "decodes, targets = GreedyDecoder(matrix, labels_indecies, [len(labels_indecies[0])])\n",
    "\n",
    "assert decodes[0] == 'there se ms no good reason for believing that twillc ange'\n",
    "assert targets[0] == 'there seems no good reason for believing that it will change'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "gvc1msqg6viwm3iwt79xy"
   },
   "source": [
    "## Seminar Ends and Homework Begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "4i95bg5u0c4pj26vvkbxyc"
   },
   "outputs": [],
   "source": [
    "#!L\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "notebookId": "ad46a522-5341-4555-ba42-195b12c06985",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
