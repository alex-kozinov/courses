{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "filepath = 'data/rus_eng_small.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    \"\"\"\n",
    "    Класс реализует разбор предложений на слова и построение индекса слов\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.n_words = len(self.index2word)\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "она экономически независима от своих родителей .\tshe is economically independent of her parents .\r\n",
      "она направила наши усилия в нужном направлении .\tshe steered our efforts in the right direction .\r\n",
      "на этом заводе производят телевизоры .\tthey are manufacturing tv sets in this factory .\r\n",
      "она всегда жалуется из за моей маленькой зарплаты .\tshe is always complaining about my small salary .\r\n",
      "они стоят там и едят чипсы .\tthey are standing there and eating potato chips .\r\n",
      "мне не удаётся скомпилировать эту программу .\ti m having some problems compiling this software .\r\n",
      "она улыбнулась в ответ на его нежный взгляд .\tshe smiled in response to his affectionate glance .\r\n",
      "она проводит каждое воскресенье со своей бабушкой .\tshe spends time with her grandmother every sunday .\r\n",
      "каждую субботу после обеда она играет в теннис .\tshe spends every saturday afternoon playing tennis .\r\n",
      "после аварии она перестала бывать на людях .\tshe stopped appearing in public after her accident .\r\n"
     ]
    }
   ],
   "source": [
    "!tail {filepath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs():\n",
    "    \"\"\"\n",
    "    Загрузка параллельного корпуса\n",
    "    \"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    pairs = []\n",
    "    # Read the file and split into lines\n",
    "    with open(filepath) as f:\n",
    "        for l in tqdm_notebook(f):\n",
    "            pair = [s for s in l.rstrip('\\n').split('\\t')]\n",
    "            pairs.append(pair)\n",
    "\n",
    "    return Lang('rus'), Lang('eng'), pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a296c63e036f4f228ab6fe270da2c01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read 19288 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 8960\n",
      "eng 3914\n",
      "['мы пытаемся работать .', 'we re trying to work .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData():\n",
    "    \"\"\"\n",
    "    Чтение корпуса и инициализация словарей\n",
    "    \"\"\"\n",
    "    input_lang, output_lang, pairs = readLangs()\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData()\n",
    "MAX_LENGTH = 10\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    Предложение в последовательность индексов слов\n",
    "    \"\"\"\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    Предложение в pytorch тензор\n",
    "    \"\"\"\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    \"\"\"\n",
    "    Пара параллельных предложений во входной и целевой тензоры\n",
    "    \"\"\"\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Модуль рекуррентного энкодера входного предложения\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, nlayers, hidden_size):\n",
    "        \"\"\"\n",
    "        :param input_size - размер словаря входных текстов\n",
    "        :param nlayers - число рекуррентных слоев\n",
    "        :param hidden_size - размер вектора состояния рекуррентного слоя\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, nlayers)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        :param x: [T,B] - входной тензор размерностью timestep на batch\n",
    "        :param hidden - состояние рнн слоя\n",
    "        :return output: [T,B,C], hidden - С=hidden_size, возвращается только последний hidden state\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"Инициализируем состояние LSTM нулями\"\"\"\n",
    "        return torch.zeros(self.nlayers, 1, self.hidden_size, device=device), \\\n",
    "               torch.zeros(self.nlayers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Модуль рекуррентного декодера\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, nlayers, output_size):\n",
    "        \"\"\"\n",
    "        :param hidden_size - размер вектора состояния рекуррентного слоя\n",
    "        :param nlayers - число рекуррентных слоев\n",
    "        :param output_size - размер словаря выходных текстов\n",
    "        \"\"\"\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, nlayers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, hidden, _):\n",
    "        \"\"\"\n",
    "        :param x: [T,B] - входной тензор размерностью timestep на batch\n",
    "        :param hidden - состояние рнн слоя\n",
    "        :return output: [T,B,C], hidden - С=hidden_size, возвращается только последний hidden state\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        logits = self.out(output)\n",
    "        output = self.softmax(logits)\n",
    "        return output, hidden, None\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"Инициализируем состояние LSTM нулями\"\"\"\n",
    "        return torch.zeros(self.nlayers, 1, self.hidden_size, device=device), \\\n",
    "               torch.zeros(self.nlayers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Декодер с механизмом внимания dot-product attention\n",
    "    T1 - шаги входной последовательности\n",
    "    T2 - шаги выходной последовательности\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, nlayers, output_size):\n",
    "        \"\"\"\n",
    "        :param hidden_size - размер вектора состояния рекуррентного слоя\n",
    "        :param nlayers - число рекуррентных слоев\n",
    "        :param output_size - размер словаря выходных текстов\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers = nlayers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.rnn = nn.LSTM(self.hidden_size, self.hidden_size, nlayers)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        :param x: [T2,B] - входной тензор с предыдущими словами размерностью timestep на batch\n",
    "        :param hidden [1, B, C] - состояние рнн слоя\n",
    "        :param encoder_outputs [T1,B,C] - выходы всех шагов энкодера\n",
    "        :return output: [T2,B,C], hidden - С=hidden_size, возвращается только последний hidden state\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x) # [T2,B,C]\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1) # [B,T1,C]\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(x.size(0)):\n",
    "            h_t = hidden[0].transpose(0, 1).transpose(1, -1) # [B, C, 1]\n",
    "\n",
    "            context, attn_weights = self.attention(encoder_outputs, h_t)\n",
    "        \n",
    "            e = embedded[i].unsqueeze(0)\n",
    "            output = torch.cat((e, context), dim=-1) # [[B,1,C];[B,1,C]] -> [B,1,C*2]\n",
    "            output = self.attn_combine(output).transpose(0,1) # [B,1,C*2] * [C*2,C] = [B,1,C] -transpose-> [1,B,C]\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "            logits = self.out(output)\n",
    "            output = F.log_softmax(logits, dim=-1)\n",
    "            outputs.append(output)\n",
    "            \n",
    "        output = torch.cat(outputs, dim=0)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def attention(self, encoder_outputs, h):\n",
    "        # bmm is the batch matrix multiplication. \n",
    "        # The first dimension of arguments is the batch dimension and should be the same\n",
    "        # [B,T1,C]x[B,C,1] -> B [T1,C]x[C,1] = [B,T1,1]\n",
    "        attn_weights = F.softmax(torch.bmm(encoder_outputs, h), dim=-2) \n",
    "\n",
    "        # Для каждой позиции выхода веса содержат значения для всех позиций входа T1\n",
    "        # В таком случае взвешенная сумма может быть посчитана за одно матричное умножение\n",
    "        # [B,1,T1]x[B,T1,C] -> B [1,T1]x[T1,C] = [B, 1, C]\n",
    "        context = torch.bmm(attn_weights.transpose(1,-1), encoder_outputs)\n",
    "        # на выходе имеем вектор контекста размерностью C для каждой позиции выхода t2\n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, \n",
    "          optimizer,  criterion, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Прогоняем forward и backward pass на одном батче\n",
    "    \"\"\"\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden # STATE TRANSFER\n",
    "    \n",
    "    if teacher_forcing_ratio == 1.: # use fast parallel mode\n",
    "        decoder_input = torch.cat([decoder_input, target_tensor[:-1]], dim=0)\n",
    "        decoder_outputs, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_outputs = decoder_outputs.squeeze()\n",
    "        loss += criterion(decoder_outputs, target_tensor.squeeze())\n",
    "        loss_value = loss.item()\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_output = decoder_output.view(decoder_output.size(0), -1)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_tensor[di].unsqueeze(0)  # Teacher forcing\n",
    "            else:\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.detach()\n",
    "        loss_value =  loss.item() / target_length\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(encoder, decoder, n_iters, print_every=1000, plot_every=100):\n",
    "    \"\"\"\n",
    "    Цикл тренировки\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    for i in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[i - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        if i > n_iters / 2:\n",
    "            teacher_forcing_ratio = (n_iters - i) / n_iters\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if i % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            dt = time_since(start, i / n_iters)\n",
    "            print('%s (%d %d%%) %.4f' % (dt, i, i / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if i % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    show_plot(plot_losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Цикл тестирования\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden # STATE TRANSFER\n",
    "    \n",
    "        decoded_words = []\n",
    "        decoder_attentions = []\n",
    "        for di in range(max_length):\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions.append(decoder_attention)\n",
    "            decoder_output = decoder_output.view(decoder_output.size(0), -1)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.detach()\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "            word = output_lang.index2word[topi.item()]\n",
    "            decoded_words.append(word)\n",
    "\n",
    "        return decoded_words, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007ca4a790cb4d4caa5427532c1d3949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='prepare set', max=40000, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters=40000\n",
    "training_pairs = [tensorsFromPair(random.choice(pairs)) for i in tqdm_notebook(range(n_iters), desc='prepare set')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, 1, hidden_size).to(device)\n",
    "decoder = AttnDecoder(hidden_size, 1, output_lang.n_words).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1.\n",
    "learning_rate=0.001\n",
    "optimizer = optim.Adam(list(encoder.parameters())+list(decoder.parameters()), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train attention seq2seq\n",
      "0m 45s (- 14m 18s) (2000 5%) 2.9839\n",
      "1m 14s (- 11m 10s) (4000 10%) 2.4279\n",
      "1m 52s (- 10m 40s) (6000 15%) 2.2564\n",
      "2m 37s (- 10m 31s) (8000 20%) 2.0926\n",
      "3m 24s (- 10m 14s) (10000 25%) 2.0371\n",
      "3m 56s (- 9m 12s) (12000 30%) 1.8566\n",
      "4m 39s (- 8m 39s) (14000 35%) 1.8152\n",
      "5m 16s (- 7m 55s) (16000 40%) 1.7765\n",
      "5m 55s (- 7m 14s) (18000 45%) 1.6435\n",
      "6m 23s (- 6m 23s) (20000 50%) 1.5987\n",
      "7m 5s (- 5m 48s) (22000 55%) 1.5804\n",
      "7m 56s (- 5m 17s) (24000 60%) 1.5797\n",
      "8m 42s (- 4m 41s) (26000 65%) 1.4962\n",
      "9m 32s (- 4m 5s) (28000 70%) 1.4456\n",
      "10m 13s (- 3m 24s) (30000 75%) 1.4167\n",
      "11m 0s (- 2m 45s) (32000 80%) 1.4181\n",
      "11m 49s (- 2m 5s) (34000 85%) 1.3813\n",
      "12m 22s (- 1m 22s) (36000 90%) 1.3488\n",
      "12m 55s (- 0m 40s) (38000 95%) 1.3018\n",
      "13m 35s (- 0m 0s) (40000 100%) 1.3008\n"
     ]
    }
   ],
   "source": [
    "print('train attention seq2seq')\n",
    "run_training(encoder, decoder, n_iters, print_every=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train attention seq2seq\n",
      "0m 41s (- 13m 12s) (2000 5%) 1.2037\n",
      "1m 10s (- 10m 32s) (4000 10%) 1.1937\n",
      "1m 37s (- 9m 14s) (6000 15%) 1.1577\n",
      "2m 5s (- 8m 21s) (8000 20%) 1.1137\n",
      "2m 32s (- 7m 38s) (10000 25%) 1.1449\n"
     ]
    }
   ],
   "source": [
    "print('train attention seq2seq')\n",
    "run_training(encoder, decoder, n_iters, print_every=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_randomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# давайте посмотрим на что похож attention\n",
    "text = \"я очень осторожна .\"\n",
    "output_words, attentions = evaluate(encoder, decoder, text)\n",
    "print(attentions[0].size(),attentions[1].size())\n",
    "attentions = torch.cat(attentions).squeeze().cpu()\n",
    "plt.matshow(attentions.numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    \"\"\"\n",
    "    Выведем attention более детально, подписав токены в позициях входной и выходной последовательностей\n",
    "    \"\"\"\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split() +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence)\n",
    "    attentions = torch.cat(attentions).squeeze().cpu()\n",
    "    print(attentions.size())\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention(\"я очень осторожна .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention(\"я бы выпил .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
