{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Lab3_DL_parts_4_and_5_optional.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtPnYqncDGmX",
        "colab_type": "text"
      },
      "source": [
        "# Lab 3: final challenges\n",
        "\n",
        "__Вам предлагается решить задачу классификации сигналов (вы уже встречались с ней во второй лабораторной работе) или задачу классификации изображений. Или обе ;)__\n",
        "\n",
        "__Выполнение этих заданий не является обязательным, но позитивно повлияет на вашу итоговую оценку. Успехов!__\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYmMofXPFjlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import pylab\n",
        "import warnings as w\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rcParams.update({'font.size':14})\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Vqo9UYEB2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "3d4bc3c4-5cd2-42cc-c580-da6756c93eca"
      },
      "source": [
        "def LOG(text):\n",
        "    print(text)\n",
        "    print('-'*70)\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    USE_COLAB = True\n",
        "except:\n",
        "    USE_COLAB = False\n",
        "\n",
        "if USE_COLAB:\n",
        "    LOG(\"\"\"Don't forget to avoid disconnections:\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicking\"); \n",
        "    document.querySelector(\"colab-connect-button\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "    \"\"\")\n",
        "\n",
        "WORK_DIR = './'\n",
        "if USE_COLAB:\n",
        "    from google.colab import files, drive\n",
        "    WORK_DIR = '/content/drive/'\n",
        "    drive.mount(WORK_DIR)\n",
        "    WORK_DIR += 'My Drive/projects/lab-3-dogs/'\n",
        "LOG(f\"Working directory is {WORK_DIR}\")\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "LOG(f'Using device is {device}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Don't forget to avoid disconnections:\n",
            "function ClickConnect(){\n",
            "    console.log(\"Clicking\"); \n",
            "    document.querySelector(\"colab-connect-button\").click() \n",
            "}\n",
            "setInterval(ClickConnect,60000)\n",
            "    \n",
            "----------------------------------------------------------------------\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Working directory is /content/drive/My Drive/projects/lab-3-dogs/\n",
            "----------------------------------------------------------------------\n",
            "Using device is cuda:0\n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJF5mqbfDGmY",
        "colab_type": "text"
      },
      "source": [
        "## Part 4. HAR classification with raw data (2+ points)\n",
        "__Disclaimer__: Это опциональная часть задания. Здесь придется экспериментировать, подбирать оптимальную структуру сети для решения задачи и активно искать подскзаки в сети.\n",
        "\n",
        "\n",
        "Данное задание составлено на основе данного [поста](https://burakhimmetoglu.com/2017/08/22/time-series-classification-with-tensorflow/). С помощью вручную сгенерированных фичей и классических подходов задача распознования движений была решена с точностью 96%. \n",
        "\n",
        "Также будет полезным изучить [вот этот](https://github.com/healthDataScience/deep-learning-HAR), а так же [вот этот репозиторий](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition), где к данной задаче рассматривается несколько подходов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgZN6u2PDGmh",
        "colab_type": "text"
      },
      "source": [
        "Вернемся к задаче классификации движений на основе [данных](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) из репозитория UCI ([прямая ссылка на скачивание](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip)). \n",
        "\n",
        "В этот раз будем работать с исходными, а не предобработанными данными. Данные представляют собой сигналы с гироскопа и акселерометра, закрепленного на теле человека. Каждому семплу соотвествует 9 связанных временных рядов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9jfJsD5DGmh",
        "colab_type": "text"
      },
      "source": [
        "В начале приведена визуализация данных на основе PCA над вручную сгенерированными признаками. Для отрисовки графиков (цвет и легенда) нам также понадобятся метки классов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHGBUYo7DGmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_with_engineered_features = np.genfromtxt(os.path.join(\"UCI HAR Dataset\", \"train\", \"X_train.txt\"))\n",
        "y_train = np.genfromtxt(os.path.join(\"UCI HAR Dataset\", \"train\", \"y_train.txt\"))\n",
        "\n",
        "y_train_list = list(y_train)\n",
        "X_unique = np.array([X_train_with_engineered_features[y_train_list.index(l)]\n",
        "                             for l in sorted(list(set(y_train)))])\n",
        "\n",
        "legend_labels = [\"WALKING\", \"WALKING.UP\", \"WALKING.DOWN\", \"SITTING\", \"STANDING\", \"LAYING\"]\n",
        "colors_list = ['red', 'blue', 'green', 'orange', 'cyan', 'magenta']\n",
        "mapped_colors = [colors_list[int(i)-1] for i in y_train]\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "\n",
        "X_train_pca = pca.fit_transform(X_train_with_engineered_features)\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "pylab.scatter(X_train_pca[:, 0], X_train_pca[:, 1],\n",
        "             c=mapped_colors)\n",
        "plt.grid()\n",
        "for idx, x in enumerate(pca.transform(X_unique)):\n",
        "    plt.scatter(x[0], \n",
        "                x[1], \n",
        "                c=colors_list[idx], \n",
        "                label=legend_labels[idx])\n",
        "plt.xlabel('First principal component')\n",
        "plt.ylabel('Second principal component')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRrcX3Y1DGml",
        "colab_type": "text"
      },
      "source": [
        "#### Предобработка данных\n",
        "Предобработка сделана за нас автором [данного репозитория](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition). Будьте осторожны с путями."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75q-VgThDGmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Useful Constants\n",
        "\n",
        "# Those are separate normalised input features for the neural network\n",
        "INPUT_SIGNAL_TYPES = [\n",
        "    \"body_acc_x_\",\n",
        "    \"body_acc_y_\",\n",
        "    \"body_acc_z_\",\n",
        "    \"body_gyro_x_\",\n",
        "    \"body_gyro_y_\",\n",
        "    \"body_gyro_z_\",\n",
        "    \"total_acc_x_\",\n",
        "    \"total_acc_y_\",\n",
        "    \"total_acc_z_\"\n",
        "]\n",
        "\n",
        "# Output classes to learn how to classify\n",
        "LABELS = [\n",
        "    \"WALKING\", \n",
        "    \"WALKING_UPSTAIRS\", \n",
        "    \"WALKING_DOWNSTAIRS\", \n",
        "    \"SITTING\", \n",
        "    \"STANDING\", \n",
        "    \"LAYING\"\n",
        "]\n",
        "\n",
        "DATA_PATH = \"./\"\n",
        "\n",
        "DATASET_PATH = DATA_PATH + \"UCI HAR Dataset/\"\n",
        "print(\"\\n\" + \"Dataset is now located at: \" + DATASET_PATH)\n",
        "\n",
        "TRAIN = \"train/\"\n",
        "TEST = \"test/\"\n",
        "\n",
        "\n",
        "# Load \"X\" (the neural network's training and testing inputs)\n",
        "\n",
        "def load_X(X_signals_paths):\n",
        "    X_signals = []\n",
        "    \n",
        "    for signal_type_path in X_signals_paths:\n",
        "        file = open(signal_type_path, 'r')\n",
        "        # Read dataset from disk, dealing with text files' syntax\n",
        "        X_signals.append(\n",
        "            [np.array(serie, dtype=np.float32) for serie in [\n",
        "                row.replace('  ', ' ').strip().split(' ') for row in file\n",
        "            ]]\n",
        "        )\n",
        "        file.close()\n",
        "    \n",
        "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
        "\n",
        "X_train_signals_paths = [\n",
        "    os.path.join(*[DATASET_PATH, TRAIN, \"Inertial Signals/\", signal+\"train.txt\"]) for signal in INPUT_SIGNAL_TYPES\n",
        "]\n",
        "X_test_signals_paths = [\n",
        "    os.path.join(*[DATASET_PATH, TEST, \"Inertial Signals/\", signal+\"test.txt\"]) for signal in INPUT_SIGNAL_TYPES\n",
        "]\n",
        "\n",
        "X_train = load_X(X_train_signals_paths)\n",
        "X_test = load_X(X_test_signals_paths)\n",
        "\n",
        "\n",
        "# Load \"y\" (the neural network's training and testing outputs)\n",
        "\n",
        "def load_y(y_path):\n",
        "    file = open(y_path, 'r')\n",
        "    # Read dataset from disk, dealing with text file's syntax\n",
        "    y_ = np.array(\n",
        "        [elem for elem in [\n",
        "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
        "        ]], \n",
        "        dtype=np.int32\n",
        "    )\n",
        "    file.close()\n",
        "    \n",
        "    # Substract 1 to each output class for friendly 0-based indexing \n",
        "    return y_ - 1\n",
        "\n",
        "y_train_path = os.path.join(DATASET_PATH, TRAIN, \"y_train.txt\")\n",
        "y_test_path = os.path.join(DATASET_PATH, TEST, \"y_test.txt\")\n",
        "\n",
        "y_train = load_y(y_train_path)\n",
        "y_test = load_y(y_test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsOBX5iuDGmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input Data \n",
        "\n",
        "training_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\n",
        "test_data_count = len(X_test)  # 2947 testing series\n",
        "n_steps = len(X_train[0])  # 128 timesteps per series\n",
        "n_input = len(X_train[0][0])  # 9 input parameters per timestep\n",
        "\n",
        "\n",
        "# LSTM Neural Network's internal structure\n",
        "\n",
        "n_hidden = 32 # Hidden layer num of features\n",
        "n_classes = 6 # Total classes (should go up, or should go down)\n",
        "\n",
        "\n",
        "# Some debugging info\n",
        "\n",
        "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
        "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
        "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
        "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFs9fEe6DGmt",
        "colab_type": "text"
      },
      "source": [
        "#### Построение сети и эксперименты. (100% +)\n",
        "\n",
        "__Ваша задача - построить сеть, которая решит задачу классификации с точностью (`accuracy`) не менее 86%.__\n",
        "Разбалловка следующая:\n",
        "* $=$86% - 2 points\n",
        "* $>=$89% - 2.5 points\n",
        "* $>=$91% - 3 points\n",
        "\n",
        "\n",
        "__Warning!__ В сети существует несколько решений данной задачи с использованием различных фреймворков. При проверке это будет учитываться, так что свое решение нужно будет объяснить. Пожалуйста, не копируйте бездумно код, такие задания будут оценены 0 баллов. Если задача не решается - можете обратиться к заданию по классификации изображений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfCUdcQUDGmt",
        "colab_type": "text"
      },
      "source": [
        "После выполнения задания заполните небольшой отчет об экспериментах вида \"Я пробовал(а) ... подходы и получил(а) ... результаты. Наконец, после N+1 чашки кофе/бессонной ночи у меня получилось, и весь секрет был в ...\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5VU6eZrDGmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your experiments here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vjHIwwXDGmx",
        "colab_type": "text"
      },
      "source": [
        "## Part 5. Dogs classification (2+ points)\n",
        "__Disclaimer__: Это опциональная часть задания. Здесь придется экспериментировать, подбирать оптимальную структуру сети для решения задачи и активно искать подскзаки в сети.\n",
        "\n",
        "Предлагаем вам решить задачу классификации пород собак. Вы можете обучить сеть с нуля или же воспользоваться методом fine-tuning'а. Полезная ссылка на [предобученные модели](https://pytorch.org/docs/stable/torchvision/models.html).\n",
        "\n",
        "Данные можно скачать [отсюда](https://www.dropbox.com/s/vgqpz2f1lolxmlv/data.zip?dl=0). Датасет представлен 50 классами пород собак, которые можно найти в папке train в соответствующих директориях. При сдаче данной части задания вместе с ноутбуком необходимо отправить .csv-файл с предсказаниями классов тестовой выборки в формате: <имя изображения>,<метка класса> по одному объекту на строку. Ниже приведите код ваших экспериментов и короткий вывод по их результатам.\n",
        "\n",
        "Будут оцениваться качество классификации (accuracy) на тестовой выборке (2 балла) и проведенные эксперименты (1 балл).\n",
        "Разбалловка следующая:\n",
        "* $>=$93% - 2 points\n",
        "* $>=$84% - 1.5 points\n",
        "* $>=$70% - 0.75 points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG5DPsjnG8c0",
        "colab_type": "text"
      },
      "source": [
        "### Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T-uczeLcK0T",
        "colab_type": "text"
      },
      "source": [
        "#### Извлечём изображения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkDlZoouJeao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e0c31758-b68d-439b-ef5a-9e9c798e9f6b"
      },
      "source": [
        "file_name = WORK_DIR + \"data.zip\"\n",
        "!unzip \"$file_name\" > /dev/null\n",
        "!ls data/\n",
        "data_path = 'data/'"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace data/train/32/109.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6cDVonycRCH",
        "colab_type": "text"
      },
      "source": [
        "#### Изучим размеры картинок"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnEX3ySZbtCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(data_path, 'train')\n",
        "test_dir = os.path.join(data_path, 'test')\n",
        "widths = []\n",
        "heights = []\n",
        "\n",
        "for target_folder in os.listdir(train_dir):\n",
        "    target_dir = os.path.join(train_dir, target_folder)\n",
        "    for image_name in os.listdir(target_dir):\n",
        "        image_path = os.path.join(target_dir, image_name)\n",
        "        image = Image.open(image_path)\n",
        "        widths.append(image.width)\n",
        "        heights.append(image.height)\n",
        "widths = np.array(widths)\n",
        "heights = np.array(heights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZvQE9qTcfxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9c034cc8-0a5e-4b53-dcd3-d71e263ed762"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(widths, heights)\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgbhzJq_dLPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b1d3ab9b-e31f-468b-f626-daaf050cfbbc"
      },
      "source": [
        "plt.figure()\n",
        "plt.hist(np.max(np.vstack([widths, heights]), axis=0) / np.min(np.vstack([widths, heights]), axis=0))\n",
        "plt.show()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmbBM1oGG7KN",
        "colab_type": "text"
      },
      "source": [
        "#### **Вывод\n",
        "\n",
        "Можно заметить, что исходные фотографии различных размеров, причём число тех, у которых высота больше ширины, примерно столько же как и тех, у которых ширина больше высоты. Поэтому наша будущая модель будет принимать квадратное изображение. Размер будет $224 \\times 224$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHjxDAIKR6vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a, b, c = load_dataset(\"data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNpRMyxATOt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset():\n",
        "    data_path = 'data/train/'\n",
        "    train_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=torchvision.transforms.ToTensor()\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=64,\n",
        "        num_workers=0,\n",
        "        shuffle=True\n",
        "    )\n",
        "    return train_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up2ycDfZTxad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "32c202d6-20aa-460f-c6e5-fb01a9d4a682"
      },
      "source": [
        "for batch_idx, (data, target) in enumerate(load_dataset()):\n",
        "    data\n",
        "    break"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-d15632138fcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 352, 500] at entry 0 and [3, 330, 500] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtK1M4ThQzBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "outputId": "438aab21-d95d-480a-bb13-dbb4bacb210b"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "zeros(shape, dtype=float, order='C')\n",
            "\n",
            "    Return a new array of given shape and type, filled with zeros.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    shape : int or tuple of ints\n",
            "        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n",
            "    dtype : data-type, optional\n",
            "        The desired data-type for the array, e.g., `numpy.int8`.  Default is\n",
            "        `numpy.float64`.\n",
            "    order : {'C', 'F'}, optional, default: 'C'\n",
            "        Whether to store multi-dimensional data in row-major\n",
            "        (C-style) or column-major (Fortran-style) order in\n",
            "        memory.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    out : ndarray\n",
            "        Array of zeros with the given shape, dtype, and order.\n",
            "\n",
            "    See Also\n",
            "    --------\n",
            "    zeros_like : Return an array of zeros with shape and type of input.\n",
            "    empty : Return a new uninitialized array.\n",
            "    ones : Return a new array setting values to one.\n",
            "    full : Return a new array of given shape filled with value.\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    >>> np.zeros(5)\n",
            "    array([ 0.,  0.,  0.,  0.,  0.])\n",
            "\n",
            "    >>> np.zeros((5,), dtype=int)\n",
            "    array([0, 0, 0, 0, 0])\n",
            "\n",
            "    >>> np.zeros((2, 1))\n",
            "    array([[ 0.],\n",
            "           [ 0.]])\n",
            "\n",
            "    >>> s = (2,2)\n",
            "    >>> np.zeros(s)\n",
            "    array([[ 0.,  0.],\n",
            "           [ 0.,  0.]])\n",
            "\n",
            "    >>> np.zeros((2,), dtype=[('x', 'i4'), ('y', 'i4')]) # custom dtype\n",
            "    array([(0, 0), (0, 0)],\n",
            "          dtype=[('x', '<i4'), ('y', '<i4')])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHoPUnASLm43",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7370ca7-f2fc-4e1e-cbd7-e53c56e3e9a2"
      },
      "source": [
        "img.width"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_rf3I71GeUK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f191446-8b5f-4dd2-950d-2da3a2e8730f"
      },
      "source": [
        "img.height"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J97khO8yLsxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "5c24171b-5325-4960-edc1-4a0cb35681f3"
      },
      "source": [
        "[f for f in os.listdir('data/train')]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['19',\n",
              " '48',\n",
              " '14',\n",
              " '9',\n",
              " '24',\n",
              " '31',\n",
              " '7',\n",
              " '1',\n",
              " '28',\n",
              " '11',\n",
              " '26',\n",
              " '33',\n",
              " '29',\n",
              " '10',\n",
              " '39',\n",
              " '40',\n",
              " '18',\n",
              " '41',\n",
              " '46',\n",
              " '22',\n",
              " '42',\n",
              " '21',\n",
              " '20',\n",
              " '49',\n",
              " '37',\n",
              " '38',\n",
              " '2',\n",
              " '12',\n",
              " '25',\n",
              " '35',\n",
              " '34',\n",
              " '0',\n",
              " '45',\n",
              " '6',\n",
              " '3',\n",
              " '44',\n",
              " '23',\n",
              " '8',\n",
              " '15',\n",
              " '47',\n",
              " '17',\n",
              " '43',\n",
              " '13',\n",
              " '32',\n",
              " '30',\n",
              " '5',\n",
              " '4',\n",
              " '27',\n",
              " '36',\n",
              " '16']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KvG_iU0NAgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}